{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d379dd",
   "metadata": {},
   "source": [
    "## Lecture 18: Handling Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5190b54",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c1375",
   "metadata": {},
   "source": [
    "1. [Introduction](#intro)\n",
    "2. [Algorithmic Level Approaches](#algo)\n",
    "3. [Data Level Approaches I (Undersampling)](#undersampling)\n",
    "    1. [Random Undersampling](#undersampling)\n",
    "    2. [NearMiss](#nearmiss)\n",
    "    3. [TomekLinks](#tomeklinks)\n",
    "4. [Data Level Approaches II (Oversampling)](#oversampling)\n",
    "    1. [Random Oversampling](#oversampling)\n",
    "    2. [SMOTE](#SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba7e6b",
   "metadata": {},
   "source": [
    "## Introduction<a id=\"intro\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00cbda",
   "metadata": {},
   "source": [
    "Data imbalance occurs when class distributions in a dataset are skewed, with one class significantly outnumbering others.\n",
    "This challenge is prevalent in various applications, including:\n",
    "- Fraud Detection\n",
    "- Medical Diagnosis\n",
    "- Text Classification\n",
    "- Image Recognition\n",
    "\n",
    "**Consequences:**\n",
    "- Models prioritize overall accuracy, often favoring the majority class.\n",
    "- This bias leads to underrepresentation of the minority class, resulting in:\n",
    "- Skewed predictions\n",
    "- Poor generalization\n",
    "\n",
    "Please refer to [presentation](https://drive.google.com/file/d/1-BLvqwQuIN95GCKwTTD2Sa_t8V24qeMh/view?usp=drive_link) for more theoretical notes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9a13a",
   "metadata": {},
   "source": [
    "We will be using a dataset of card transactions. You can find the data and a complete dataset description at this [link](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c5a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e89cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f8ee7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498143c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "145a0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a929663d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74de3673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99.827251\n",
       "1     0.172749\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a272b9d",
   "metadata": {},
   "source": [
    "We observe that only 0.17% of the transactions are fraudulent (positive class), indicating a highly imbalanced dataset.\n",
    "\n",
    "We'll begin with a brief data cleaning process before moving on to model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2e129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe84fb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>1.772925e-15</td>\n",
       "      <td>9.289524e-16</td>\n",
       "      <td>-1.803266e-15</td>\n",
       "      <td>1.674888e-15</td>\n",
       "      <td>1.475621e-15</td>\n",
       "      <td>3.501098e-15</td>\n",
       "      <td>1.392460e-15</td>\n",
       "      <td>-7.466538e-16</td>\n",
       "      <td>4.258754e-16</td>\n",
       "      <td>9.019919e-16</td>\n",
       "      <td>5.126845e-16</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>1.088850e+00</td>\n",
       "      <td>1.020713e+00</td>\n",
       "      <td>9.992014e-01</td>\n",
       "      <td>9.952742e-01</td>\n",
       "      <td>9.585956e-01</td>\n",
       "      <td>9.153160e-01</td>\n",
       "      <td>8.762529e-01</td>\n",
       "      <td>8.493371e-01</td>\n",
       "      <td>8.381762e-01</td>\n",
       "      <td>8.140405e-01</td>\n",
       "      <td>7.709250e-01</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>-2.458826e+01</td>\n",
       "      <td>-4.797473e+00</td>\n",
       "      <td>-1.868371e+01</td>\n",
       "      <td>-5.791881e+00</td>\n",
       "      <td>-1.921433e+01</td>\n",
       "      <td>-4.498945e+00</td>\n",
       "      <td>-1.412985e+01</td>\n",
       "      <td>-2.516280e+01</td>\n",
       "      <td>-9.498746e+00</td>\n",
       "      <td>-7.213527e+00</td>\n",
       "      <td>-5.449772e+01</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>-5.354257e-01</td>\n",
       "      <td>-7.624942e-01</td>\n",
       "      <td>-4.055715e-01</td>\n",
       "      <td>-6.485393e-01</td>\n",
       "      <td>-4.255740e-01</td>\n",
       "      <td>-5.828843e-01</td>\n",
       "      <td>-4.680368e-01</td>\n",
       "      <td>-4.837483e-01</td>\n",
       "      <td>-4.988498e-01</td>\n",
       "      <td>-4.562989e-01</td>\n",
       "      <td>-2.117214e-01</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>-9.291738e-02</td>\n",
       "      <td>-3.275735e-02</td>\n",
       "      <td>1.400326e-01</td>\n",
       "      <td>-1.356806e-02</td>\n",
       "      <td>5.060132e-02</td>\n",
       "      <td>4.807155e-02</td>\n",
       "      <td>6.641332e-02</td>\n",
       "      <td>-6.567575e-02</td>\n",
       "      <td>-3.636312e-03</td>\n",
       "      <td>3.734823e-03</td>\n",
       "      <td>-6.248109e-02</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>4.539234e-01</td>\n",
       "      <td>7.395934e-01</td>\n",
       "      <td>6.182380e-01</td>\n",
       "      <td>6.625050e-01</td>\n",
       "      <td>4.931498e-01</td>\n",
       "      <td>6.488208e-01</td>\n",
       "      <td>5.232963e-01</td>\n",
       "      <td>3.996750e-01</td>\n",
       "      <td>5.008067e-01</td>\n",
       "      <td>4.589494e-01</td>\n",
       "      <td>1.330408e-01</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>2.374514e+01</td>\n",
       "      <td>1.201891e+01</td>\n",
       "      <td>7.848392e+00</td>\n",
       "      <td>7.126883e+00</td>\n",
       "      <td>1.052677e+01</td>\n",
       "      <td>8.877742e+00</td>\n",
       "      <td>1.731511e+01</td>\n",
       "      <td>9.253526e+00</td>\n",
       "      <td>5.041069e+00</td>\n",
       "      <td>5.591971e+00</td>\n",
       "      <td>3.942090e+01</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "                V10           V11           V12           V13           V14  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.772925e-15  9.289524e-16 -1.803266e-15  1.674888e-15  1.475621e-15   \n",
       "std    1.088850e+00  1.020713e+00  9.992014e-01  9.952742e-01  9.585956e-01   \n",
       "min   -2.458826e+01 -4.797473e+00 -1.868371e+01 -5.791881e+00 -1.921433e+01   \n",
       "25%   -5.354257e-01 -7.624942e-01 -4.055715e-01 -6.485393e-01 -4.255740e-01   \n",
       "50%   -9.291738e-02 -3.275735e-02  1.400326e-01 -1.356806e-02  5.060132e-02   \n",
       "75%    4.539234e-01  7.395934e-01  6.182380e-01  6.625050e-01  4.931498e-01   \n",
       "max    2.374514e+01  1.201891e+01  7.848392e+00  7.126883e+00  1.052677e+01   \n",
       "\n",
       "                V15           V16           V17           V18           V19  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   3.501098e-15  1.392460e-15 -7.466538e-16  4.258754e-16  9.019919e-16   \n",
       "std    9.153160e-01  8.762529e-01  8.493371e-01  8.381762e-01  8.140405e-01   \n",
       "min   -4.498945e+00 -1.412985e+01 -2.516280e+01 -9.498746e+00 -7.213527e+00   \n",
       "25%   -5.828843e-01 -4.680368e-01 -4.837483e-01 -4.988498e-01 -4.562989e-01   \n",
       "50%    4.807155e-02  6.641332e-02 -6.567575e-02 -3.636312e-03  3.734823e-03   \n",
       "75%    6.488208e-01  5.232963e-01  3.996750e-01  5.008067e-01  4.589494e-01   \n",
       "max    8.877742e+00  1.731511e+01  9.253526e+00  5.041069e+00  5.591971e+00   \n",
       "\n",
       "                V20           V21           V22           V23           V24  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   5.126845e-16  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    7.709250e-01  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min   -5.449772e+01 -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%   -2.117214e-01 -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%   -6.248109e-02 -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    1.330408e-01  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    3.942090e+01  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764b3cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum() # checking for duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376209a",
   "metadata": {},
   "source": [
    "We have 1081 duplicated rows in our dataset. Let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de953e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "408a5ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0     88.413575\n",
       "1    123.871860\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Class').Amount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "692141ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will drop time column for now, we can use it later to improve the accuracy of the model\n",
    "df = df.drop('Time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d4a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9334a2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((283726, 29), (283726,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ea33a",
   "metadata": {},
   "source": [
    "We’ll split the dataset into training, validation, and test sets with a 60/20/20% ratio. To ensure consistent class distribution across each partition, we’ll use the `stratify` parameter in `train_test_split`, preserving the proportion of instances in each class in every subset. The combined `X_train_val` set will include both training and validation data, allowing for direct use during cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f99cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81fadc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170235, 29), (56745, 29), (56746, 29))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603109f",
   "metadata": {},
   "source": [
    "We’ll start by building a logistic regression model directly on our imbalanced data to establish a baseline. Then, we’ll apply various strategies for handling data imbalance and assess the improvements. For cross-validation, we’ll use a `StratifiedKFold` object to maintain consistent class distribution across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "220630db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31ed7890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:51, 22.28s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(X_train_val, y_train_val)):\n",
    "    X_fold_train, X_fold_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
    "    \n",
    "    lr.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    y_pred = lr.predict(X_fold_val)\n",
    "    \n",
    "    recall = recall_score(y_fold_val, y_pred)\n",
    "    precision = precision_score(y_fold_val, y_pred)\n",
    "    f1 = f1_score(y_fold_val, y_pred)\n",
    "    accuracy = accuracy_score(y_fold_val, y_pred)\n",
    "    \n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    f1_scores.append(f1)\n",
    "    accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a827f100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.621474</td>\n",
       "      <td>0.857103</td>\n",
       "      <td>0.718459</td>\n",
       "      <td>0.999194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recall  Precision        F1  Accuracy\n",
       "0  0.621474   0.857103  0.718459  0.999194"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_recall = np.mean(recall_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "pd.DataFrame(data=[(average_recall, average_precision, average_f1, average_accuracy)], columns=['Recall', 'Precision', 'F1', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e6c9d",
   "metadata": {},
   "source": [
    "Let’s experiment with different prediction thresholds. By default, logistic regression classifies a sample as positive if its probability exceeds 0.5. We’ll retrain the model on the validation set and adjust the threshold to achieve a recall of 0.9 (90%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fc0077a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b04bd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = lr.predict_proba(X_val)[:, 1]\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baf92610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.77381</td>\n",
       "      <td>0.99933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recall  Precision       F1  Accuracy\n",
       "0  0.691489   0.878378  0.77381   0.99933"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original 0.5 threhsold\n",
    "recall = recall_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "pd.DataFrame(data=[(recall, precision, f1, accuracy)], columns=['Recall', 'Precision', 'F1', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c751187a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.027887</td>\n",
       "      <td>0.054106</td>\n",
       "      <td>0.947625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recall  Precision        F1  Accuracy\n",
       "0  0.904255   0.027887  0.054106  0.947625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = lr.predict_proba(X_val)[:, 1]\n",
    "y_pred = (y_prob >= 0.0015).astype(int)\n",
    "\n",
    "recall = recall_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "pd.DataFrame(data=[(recall, precision, f1, accuracy)], columns=['Recall', 'Precision', 'F1', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718f2f9",
   "metadata": {},
   "source": [
    "Setting the threshold to 0.0015 allows us to achieve a recall of 90%, meaning we identify 90% of fraudulent transactions. However, note that precision drops to 2.7%, indicating that only 2.7% of our positive predictions are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec84ee65",
   "metadata": {},
   "source": [
    "Let’s examine the confusion matrix to analyze the counts of true negatives, false positives, false negatives, and true positives.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67a3a867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53688,  2963],\n",
       "       [    9,    85]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "cm\n",
    "\n",
    "# (tn, fp, \n",
    "#  fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed620fc8",
   "metadata": {},
   "source": [
    "### Algorithm Level Approach for hanlding data imbalance<a id=\"algo\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d0a43",
   "metadata": {},
   "source": [
    "We can adjust the learning process of logistic regression to give more emphasis to the minority class by setting `class_weight='balanced'`. This approach modifies the cost function by assigning higher penalties to misclassified instances of the minority class, effectively increasing their impact on the model’s optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcbb1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51069568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:53, 22.72s/it]\n"
     ]
    }
   ],
   "source": [
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(X_train_val, y_train_val)):\n",
    "    X_fold_train, X_fold_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
    "    \n",
    "    lr.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    y_pred = lr.predict(X_fold_val)\n",
    "    \n",
    "    recall = recall_score(y_fold_val, y_pred)\n",
    "    precision = precision_score(y_fold_val, y_pred)\n",
    "    f1 = f1_score(y_fold_val, y_pred)\n",
    "    accuracy = accuracy_score(y_fold_val, y_pred)\n",
    "    \n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    f1_scores.append(f1)\n",
    "    accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94ac87ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.912526</td>\n",
       "      <td>0.05931</td>\n",
       "      <td>0.111321</td>\n",
       "      <td>0.975601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recall  Precision        F1  Accuracy\n",
       "0  0.912526    0.05931  0.111321  0.975601"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_recall = np.mean(recall_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "pd.DataFrame(data=[(average_recall, average_precision, average_f1, average_accuracy)], columns=['Recall', 'Precision', 'F1', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1072afdb",
   "metadata": {},
   "source": [
    "We observe a significant improvement in recall compared to our initial predictions. While the precision remains relatively low at 5.9%, it is still better than the unadjusted logistic regression model (without `class_weight='balanced'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323489b8",
   "metadata": {},
   "source": [
    "## Data Level Approaches. Undersampling <a id=\"undersampling\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78e019b",
   "metadata": {},
   "source": [
    "The primary data-level approaches for handling class imbalance are undersampling and oversampling. Let’s begin with undersampling.\n",
    "\n",
    "Through undersampling, we reduce the number of instances in the majority class to better balance it with the minority class. There are different undersampling strategies, with the simplest being random undersampling, which randomly removes instances from the majority class. \n",
    "\n",
    "We’ll use the `RandomUnderSampler` implementation from the `imblearn` library; please install this library if you haven’t already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "029353c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2ca16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98a7f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under, y_under = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e43a53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284\n",
       "1    284\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_under.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65510be",
   "metadata": {},
   "source": [
    "After applying the undersampler with `fit_resample` on the training set, the majority class instances are reduced to match the count of the minority class. However, since our data contains very few minority class instances (284 in the training set), undersampling may not be ideal; with such limited data, the model may struggle to learn effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783052a5",
   "metadata": {},
   "source": [
    "We'll create a pipeline that includes both the undersampling step and the model. This allows us to apply the process seamlessly to both the training and validation sets. We're using the `Pipeline` from `imblearn`, as `sklearn`'s version does not support operations that modify the number of rows in the dataset.\n",
    "\n",
    "Importantly, when using the pipeline on the validation set, we only call `predict`, ensuring that undersampling is not applied during validation. This approach is crucial, as we need to evaluate model performance on real-world data, not undersampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a2102c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_under_pipeline = Pipeline(steps=[\n",
    "    ('random_under', RandomUnderSampler(random_state=42)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=13))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "002dc267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  2.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(X_train_val, y_train_val)):\n",
    "    X_fold_train, X_fold_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
    "    \n",
    "    random_under_pipeline.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    y_pred = random_under_pipeline.predict(X_fold_val)\n",
    "    \n",
    "    recall = recall_score(y_fold_val, y_pred)\n",
    "    precision = precision_score(y_fold_val, y_pred)\n",
    "    f1 = f1_score(y_fold_val, y_pred)\n",
    "    accuracy = accuracy_score(y_fold_val, y_pred)\n",
    "    \n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    f1_scores.append(f1)\n",
    "    accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6b31b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.917895</td>\n",
       "      <td>0.039725</td>\n",
       "      <td>0.076146</td>\n",
       "      <td>0.962829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recall  Precision        F1  Accuracy\n",
       "0  0.917895   0.039725  0.076146  0.962829"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_recall = np.mean(recall_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "pd.DataFrame(data=[(average_recall, average_precision, average_f1, average_accuracy)], columns=['Recall', 'Precision', 'F1', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe053ae",
   "metadata": {},
   "source": [
    "### NearMiss undersampling<a id=\"nearmiss\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075eff32",
   "metadata": {},
   "source": [
    "Another undersampling strategy is NearMiss. It removes majority class instances that are farthest from the minority class instances, effectively keeping only those majority instances that are closest to the minority class. This approach ensures that the remaining majority samples are more representative of the decision boundary, making it easier for the model to learn the distinctions between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "790e0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "random_under_pipeline = Pipeline(steps=[\n",
    "    ('nearmiss_under', NearMiss()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=13))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7d5951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(X_train_val, y_train_val)):\n",
    "    X_fold_train, X_fold_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
    "    \n",
    "    random_under_pipeline.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    y_pred = random_under_pipeline.predict(X_fold_val)\n",
    "    \n",
    "    recall = recall_score(y_fold_val, y_pred)\n",
    "    precision = precision_score(y_fold_val, y_pred)\n",
    "    f1 = f1_score(y_fold_val, y_pred)\n",
    "    accuracy = accuracy_score(y_fold_val, y_pred)\n",
    "    \n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    f1_scores.append(f1)\n",
    "    accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "255e42f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973509</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.310644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recall  Precision        F1  Accuracy\n",
       "0  0.973509   0.002355  0.004698  0.310644"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_recall = np.mean(recall_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "pd.DataFrame(data=[(average_recall, average_precision, average_f1, average_accuracy)], columns=['Recall', 'Precision', 'F1', 'Accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774ea13",
   "metadata": {},
   "source": [
    "### Tomek Links<a id=\"tomeklinks\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94eeb7",
   "metadata": {},
   "source": [
    "Another undersampling approach is Tomek Links. This method removes the majority class sample from each identified pair of closest points (one from each class) if they form a Tomek Link, meaning they are each other’s nearest neighbors. This technique helps to clean the boundary between classes, reducing overlap and making the classes more separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d03c9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "random_under_pipeline = Pipeline(steps=[\n",
    "    ('tl_under', TomekLinks()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=13))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cde90fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [09:56, 119.23s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(X_train_val, y_train_val)):\n",
    "    X_fold_train, X_fold_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
    "    \n",
    "    random_under_pipeline.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    y_pred = random_under_pipeline.predict(X_fold_val)\n",
    "    \n",
    "    recall = recall_score(y_fold_val, y_pred)\n",
    "    precision = precision_score(y_fold_val, y_pred)\n",
    "    f1 = f1_score(y_fold_val, y_pred)\n",
    "    accuracy = accuracy_score(y_fold_val, y_pred)\n",
    "    \n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    f1_scores.append(f1)\n",
    "    accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ac8486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.62414</td>\n",
       "      <td>0.857642</td>\n",
       "      <td>0.720438</td>\n",
       "      <td>0.999198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Recall  Precision        F1  Accuracy\n",
       "0  0.62414   0.857642  0.720438  0.999198"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_recall = np.mean(recall_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "pd.DataFrame(data=[(average_recall, average_precision, average_f1, average_accuracy)], columns=['Recall', 'Precision', 'F1', 'Accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18979baf",
   "metadata": {},
   "source": [
    "## Oversampling<a id=\"oversampling\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35636284",
   "metadata": {},
   "source": [
    "Oversampling focuses on increasing the number of minority class instances to balance them with the majority class. There are several approaches to achieve this, with one of the simplest being `RandomOverSampler`, which randomly duplicates minority class samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "046b9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83203577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomOverSampler(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomOverSampler(random_state=42)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "ros.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "618551b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over, y_over = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dc81dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339902, 29)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eca92fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    169951\n",
       "1    169951\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ef28c",
   "metadata": {},
   "source": [
    "After applying random oversampling, the number of instances in the minority class has increased to match the majority class, creating a balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30aca2a",
   "metadata": {},
   "source": [
    "Let’s create a pipeline that includes both `RandomOverSampler` and `StandardScaler()`. Standardizing features can enhance the convergence speed of gradient descent in logistic regression, leading to faster model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "302d3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_over_pipeline = Pipeline(steps=[\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('random_over', RandomOverSampler(random_state=42)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=13))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd5a31df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(X_train_val, y_train_val)):\n",
    "    X_fold_train, X_fold_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
    "    \n",
    "    random_over_pipeline.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    y_pred = random_over_pipeline.predict(X_fold_val)\n",
    "    \n",
    "    recall = recall_score(y_fold_val, y_pred)\n",
    "    precision = precision_score(y_fold_val, y_pred)\n",
    "    f1 = f1_score(y_fold_val, y_pred)\n",
    "    accuracy = accuracy_score(y_fold_val, y_pred)\n",
    "    \n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    f1_scores.append(f1)\n",
    "    accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d6e3dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.912526</td>\n",
       "      <td>0.059951</td>\n",
       "      <td>0.112454</td>\n",
       "      <td>0.975892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recall  Precision        F1  Accuracy\n",
       "0  0.912526   0.059951  0.112454  0.975892"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_recall = np.mean(recall_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "pd.DataFrame(data=[(average_recall, average_precision, average_f1, average_accuracy)], columns=['Recall', 'Precision', 'F1', 'Accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f38148",
   "metadata": {},
   "source": [
    "### SMOTE<a id=\"smote\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fdd608",
   "metadata": {},
   "source": [
    "Another oversampling strategy is SMOTE (Synthetic Minority Over-sampling Technique). SMOTE generates additional instances for the minority class by creating synthetic samples. It does this by selecting instances from the minority class and interpolating between them, generating new samples that lie along the line segments connecting nearest neighbors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93f7cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "random_over_pipeline = Pipeline(steps=[\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('random_over', SMOTE(random_state=42)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=13))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef99dd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:17,  3.51s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(X_train_val, y_train_val)):\n",
    "    X_fold_train, X_fold_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]\n",
    "    \n",
    "    random_over_pipeline.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    y_pred = random_over_pipeline.predict(X_fold_val)\n",
    "    \n",
    "    recall = recall_score(y_fold_val, y_pred)\n",
    "    precision = precision_score(y_fold_val, y_pred)\n",
    "    f1 = f1_score(y_fold_val, y_pred)\n",
    "    accuracy = accuracy_score(y_fold_val, y_pred)\n",
    "    \n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    f1_scores.append(f1)\n",
    "    accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdc0e62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.915123</td>\n",
       "      <td>0.05511</td>\n",
       "      <td>0.103914</td>\n",
       "      <td>0.973619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recall  Precision        F1  Accuracy\n",
       "0  0.915123    0.05511  0.103914  0.973619"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_recall = np.mean(recall_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "pd.DataFrame(data=[(average_recall, average_precision, average_f1, average_accuracy)], columns=['Recall', 'Precision', 'F1', 'Accuracy'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
