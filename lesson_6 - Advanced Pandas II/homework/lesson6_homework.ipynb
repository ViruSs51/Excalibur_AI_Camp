{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAbIZyDN0OU0"
      },
      "outputs": [],
      "source": [
        "# make sure you have the latest version of sigmoid_check installed by running pip install sigmoid_check --upgrade\n",
        "from sigmoid_check.excalibur import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uO6BvWK0OVE",
        "outputId": "0d25ca56-f47f-420e-d723-3dd42c8181a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Extract DataFrame `df_social_media_metrics` subset for rows where 'Likes' exceed 'Shares' and store it in `highly_liked_posts`.\n",
        "@check_pandas_101\n",
        "def pandas_101(df_social_media_metrics):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"highly_liked_posts\": highly_liked_posts}\n",
        "\n",
        "pandas_101()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g73a2X530OVI",
        "outputId": "7c32b9e9-029d-4d1c-8cb6-9ad2efb604a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_product_info` to group by 'Category', computing the minimum 'Price' for each category, storing result as `min_price_by_category`.\n",
        "@check_pandas_102\n",
        "def pandas_102(df_product_info):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"min_price_by_category\": min_price_by_category}\n",
        "\n",
        "pandas_102()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbk4G_O40OVK",
        "outputId": "a22ca1b3-1cd7-4e11-9c26-c6d2ec0cb1ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Apply datetime filtering on `df_online_sessions` to store sessions in the month of January 2023 in variable `january_sessions` based on 'SessionStart'.\n",
        "@check_pandas_103\n",
        "def pandas_103(df_online_sessions):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"january_sessions\": january_sessions}\n",
        "\n",
        "pandas_103()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VExBNQ-0OVM",
        "outputId": "35425702-eacc-4dbb-aceb-86aef4b82d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_employee_entries` and fill NA in 'EntryTime' with '08:00 AM', storing the result in `filled_employee_entries`.\n",
        "@check_pandas_104\n",
        "def pandas_104(df_employee_entries):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filled_employee_entries\": filled_employee_entries}\n",
        "\n",
        "pandas_104()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj2eGHUl0OVN",
        "outputId": "846389e8-1100-4392-91ab-fbea9f7289bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Drop all columns with any NA values in DataFrame `df_transaction_records`, storing cleaned version as `non_na_transactions`.\n",
        "@check_pandas_105\n",
        "def pandas_105(df_transaction_records):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"non_na_transactions\": non_na_transactions}\n",
        "\n",
        "pandas_105()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz0ebXW50OVO",
        "outputId": "c622d45f-2b00-486d-eb50-9e776b910316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a Series `series_ascending` from a list of numbers [1, 2, 3, 4, 5], using these values as the indices as well.\n",
        "@check_pandas_106\n",
        "def pandas_106():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"series_ascending\": series_ascending}\n",
        "\n",
        "pandas_106()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ4Srlth0OVP",
        "outputId": "e3fc864b-7d22-42d5-f990-97bd2207923d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use the query method on DataFrame `df_financial_audit` to extract entries with 'Audit' == 'Complete' and 'Amount' > 10000, saving it as `completed_audits`.\n",
        "@check_pandas_107\n",
        "def pandas_107(df_financial_audit):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"completed_audits\": completed_audits}\n",
        "\n",
        "pandas_107()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV7g_2Pf0OVQ",
        "outputId": "133bfc79-cb7a-4dd2-8993-d3e9b65cf159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a custom `percent_round` function and apply it to round the 'Progress' column in DataFrame `df_student_projects` to the nearest ten, storing result as `rounded_progress`.\n",
        "@check_pandas_108\n",
        "def pandas_108(df_student_projects):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"rounded_progress\": rounded_progress}\n",
        "\n",
        "pandas_108()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fzIt3h-0OVR",
        "outputId": "5da57fbc-937e-40e8-97bc-2dbc57db1493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Extract the elements starting from the 10th index to the 20th index from `df_user_activity`, storing the result in `sampled_user_activity`.\n",
        "@check_pandas_109\n",
        "def pandas_109(df_user_activity):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sampled_user_activity\": sampled_user_activity}\n",
        "\n",
        "pandas_109()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDlv3bqC0OVS",
        "outputId": "1850c2b1-1582-4a11-89a9-fd7c30a86324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use advanced indexing to set all negative values in DataFrame `df_temperature_fluctuations` to zero, storing corrected DataFrame as `non_negative_temperatures`.\n",
        "@check_pandas_110\n",
        "def pandas_110(df_temperature_fluctuations):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"non_negative_temperatures\": non_negative_temperatures}\n",
        "\n",
        "pandas_110()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mfklfYi0OVT",
        "outputId": "61776cce-841c-4b63-ade8-dd64c9822dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# With DataFrame `df_fleet_inventory`, allocate memory efficiency by converting 'Year' column to category, saving the result as `efficient_fleet_inventory`.\n",
        "@check_pandas_111\n",
        "def pandas_111(df_fleet_inventory):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"efficient_fleet_inventory\": efficient_fleet_inventory}\n",
        "\n",
        "pandas_111()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0E1W8XL0OVT",
        "outputId": "5c6cc3a7-a01a-47c1-87e8-20b54d95d4ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_respiratory_data` to calculate cumulative maximum of 'Pulse' within groups of 'PatientID', storing it as `grouped_cumulative_max`.\n",
        "@check_pandas_112\n",
        "def pandas_112(df_respiratory_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"grouped_cumulative_max\": grouped_cumulative_max}\n",
        "\n",
        "pandas_112()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YW_GlqkY0OVU",
        "outputId": "592177d1-bdb6-4287-fe76-e81717247578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Group DataFrame `df_weather_statistics` and apply aggregation to find both 'mean' and 'std' of 'Temperature', storing multi-aggregate result as `weather_stats`.\n",
        "@check_pandas_113\n",
        "def pandas_113(df_weather_statistics):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"weather_stats\": weather_stats}\n",
        "\n",
        "pandas_113()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atQy1h9K0OVU",
        "outputId": "6a98020b-be48-47d9-b518-464f5f650978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a hierarchical index on DataFrame `df_multilayer_data` using [('Region', 'State')], saving the result as `hierarchical_multilayer`.\n",
        "@check_pandas_114\n",
        "def pandas_114(df_multilayer_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"hierarchical_multilayer\": hierarchical_multilayer}\n",
        "\n",
        "pandas_114()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-_o66ln0OVU",
        "outputId": "220e601d-7764-4ab9-c7f4-a495353ba5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Calculate the exponential moving average with a span of 10 on the 'Close' column in DataFrame `df_market_activity`, storing to `ema_market_activity`.\n",
        "@check_pandas_115\n",
        "def pandas_115(df_market_activity):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"ema_market_activity\": ema_market_activity}\n",
        "\n",
        "pandas_115()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUpAZ80C0OVV",
        "outputId": "0cdb7c3b-efa8-4760-e9cf-323a0982199a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame `df_temperature_readings` for two sensors over the year using monthly datetime index, with lineaerly increasing temperature values from 20 to 30 for Sensor1 and 15 to 25 for Sensor2.\n",
        "@check_pandas_116\n",
        "def pandas_116():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_temperature_readings\": df_temperature_readings}\n",
        "\n",
        "pandas_116()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MF7zDBh0OVV",
        "outputId": "a30bf73b-7984-4bfe-c71f-fc2421797aad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_sales_tiers` to add a 'SalesTier' column assigned by binning the 'Sales' column into 'Low', 'Medium', and 'High' categories based on [0, 5000, 10000, 15000] bins, storing as `tiered_sales`.\n",
        "@check_pandas_117\n",
        "def pandas_117(df_sales_tiers):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"tiered_sales\": tiered_sales}\n",
        "\n",
        "pandas_117()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZcNthPr0OVW",
        "outputId": "7e3d0760-0a9c-48a2-d914-5b88c42cc0d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Extract month at index of DataFrame `df_time_based_events`, storing them as a new column 'EventMonth' in the DataFrame.\n",
        "@check_pandas_118\n",
        "def pandas_118(df_time_based_events):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_time_based_events\": df_time_based_events}\n",
        "\n",
        "pandas_118()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RtB4_di0OVW",
        "outputId": "84be9217-3cff-470b-c2a0-3ea3591fb179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Given a DataFrame `df_tennis_matches`, select rows using .loc where 'MatchesPlayed' > 20 and store them as `consistent_players`.\n",
        "@check_pandas_119\n",
        "def pandas_119(df_tennis_matches):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"consistent_players\": consistent_players}\n",
        "\n",
        "pandas_119()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDH2OR__0OVX",
        "outputId": "0e013cd0-7970-424f-8b6c-081dc08600f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Utilize .iloc on DataFrame `df_daily_results` to select rows by integer location, focusing on every third row, and storing result as `every_third_result`.\n",
        "@check_pandas_120\n",
        "def pandas_120(df_daily_results):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"every_third_result\": every_third_result}\n",
        "\n",
        "pandas_120()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GBuIW3I0OVX",
        "outputId": "bc42373d-3482-4fac-fa40-1225edd94ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# From DataFrame `df_survey_responses`, combine 'Question' and 'Answer' columns into a single 'Response' column, storing the result as a Series `consolidated_responses` in the format 'Question: Answer'.\n",
        "@check_pandas_121\n",
        "def pandas_121(df_survey_responses):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"consolidated_responses\": consolidated_responses}\n",
        "\n",
        "pandas_121()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRGwF8wk0OVY",
        "outputId": "7c722085-ad20-43de-d074-a5bafd75fb07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_server_logs` to group by 'ServerID' and calculate the sum and max of 'ResponseTime', storing result as `server_response_summary`.\n",
        "@check_pandas_122\n",
        "def pandas_122(df_server_logs):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"server_response_summary\": server_response_summary}\n",
        "\n",
        "pandas_122()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UBdmq0S0OVZ",
        "outputId": "68374f58-4118-4311-ad0e-d297458e9f50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Modify DataFrame `df_machine_operating` by adding column 'Downtime' calculated from 'EndTime' minus 'StartTime', storing as `operations_with_downtime`.\n",
        "@check_pandas_123\n",
        "def pandas_123(df_machine_operating):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"operations_with_downtime\": operations_with_downtime}\n",
        "\n",
        "pandas_123()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS6Hd-sx0OVZ",
        "outputId": "af761bc2-4ac0-4139-90e0-68e073df3021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Remove duplicate rows from DataFrame `df_patient_visits`, considering only 'PatientID' and 'VisitDate', saving unique rows as `unique_patient_visits`.\n",
        "@check_pandas_124\n",
        "def pandas_124(df_patient_visits):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"unique_patient_visits\": unique_patient_visits}\n",
        "\n",
        "pandas_124()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kpcwtt_0OVa",
        "outputId": "19dcfd02-b7da-4f4a-f10a-23bd156a7ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Optimize data processing speed in DataFrame `df_satellite_data` by converting all text-based columns to category type, storing efficient version as `satellite_optimized`.\n",
        "@check_pandas_125\n",
        "def pandas_125(df_satellite_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"satellite_optimized\": satellite_optimized}\n",
        "\n",
        "pandas_125()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_osGtUKX0OVa",
        "outputId": "98c2512f-1071-4633-e250-b44e216dc098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use vectorized operations on DataFrame `df_temperature_logs` to convert 'TemperatureC' to Fahrenheit, storing the result in `temperature_fahrenheit`.\n",
        "@check_pandas_126\n",
        "def pandas_126(df_temperature_logs):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"temperature_fahrenheit\": temperature_fahrenheit}\n",
        "\n",
        "pandas_126()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmGERAtx0OVa",
        "outputId": "c4199bcd-7e34-4f85-930d-cb54bd975f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Group DataFrame `df_streaming_data` by 'UserID' and apply a lambda function to compute total view time, storing the result as `total_view_time`.\n",
        "@check_pandas_127\n",
        "def pandas_127(df_streaming_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"total_view_time\": total_view_time}\n",
        "\n",
        "pandas_127()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R-S3x120OVb",
        "outputId": "1341954c-e222-4f4f-ba84-c3e6589417e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_sales_analytics` to implement cohort analysis, calculating first purchase date and cohort index, storing result in `sales_cohorts`.\n",
        "@check_pandas_128\n",
        "def pandas_128(df_sales_analytics):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sales_cohorts\": sales_cohorts}\n",
        "\n",
        "pandas_128()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwtQlH5I0OVb",
        "outputId": "6a0c15ec-5c89-4327-d2a9-208a98e0749a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# In DataFrame `df_web_traffic`, apply conversion to 'Date' column from string to datetime, saving the updated DataFrame as `web_traffic_dates`.\n",
        "@check_pandas_129\n",
        "def pandas_129(df_web_traffic):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"web_traffic_dates\": web_traffic_dates}\n",
        "\n",
        "pandas_129()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szd0PdWm0OVb",
        "outputId": "c812d0d1-8f1b-4a5d-c807-f33af375def7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame `df_energy_savings` with datetime index representing bi-weekly dates over one year, filled with repetitive 5% and 10% energy savings, stored in 'SavingsPercent'.\n",
        "@check_pandas_130\n",
        "def pandas_130():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\\\n",
        "    return {\"df_energy_savings\": df_energy_savings}\n",
        "\n",
        "pandas_130()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuiFMNPp0OVd",
        "outputId": "4a715939-3b6c-483b-c7ef-e05997b1e336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# With DataFrame `df_vehicle_data`, apply method chaining to filter 'Type' as 'SUV' and sort by 'RecallDate', saving sorted SUVs as `sorted_suvs`.\n",
        "@check_pandas_131\n",
        "def pandas_131(df_vehicle_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sorted_suvs\": sorted_suvs}\n",
        "\n",
        "pandas_131()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2cDsKYF0OVg",
        "outputId": "b8e2e29c-e6c9-4077-db81-507e3b14e1f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Extract 'year' from 'DateAdmitted' in DataFrame `df_patient_admissions` using datetime operations, storing extracted years in `admission_years`.\n",
        "@check_pandas_132\n",
        "def pandas_132(df_patient_admissions):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"admission_years\": admission_years}\n",
        "\n",
        "pandas_132()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9LRAEM20OVh",
        "outputId": "00a1f504-9f0c-4a14-f151-42dd4d2262f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Process DataFrame `df_cost_analysis` by converting 'Amount' to USD using 'Currency' which contains the type like ['EUR', 'GBP'] conversion rates being EUR: 1.12 and GBP: 1.30, storing result as `cost_analysis_usd` with column 'Amount' in 'Currency' and 'AmountUSD' in USD.\n",
        "@check_pandas_133\n",
        "def pandas_133(df_cost_analysis):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"cost_analysis_usd\": cost_analysis_usd}\n",
        "\n",
        "pandas_133()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9l5ueub0OVi",
        "outputId": "1e2437d8-3b4c-4aa9-9b75-891d545e7764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# In DataFrame `df_logistics_data`, use rolling window of 30 days to calculate moving average inventory level, storing as `thirty_day_moving_inventory`.\n",
        "@check_pandas_134\n",
        "def pandas_134(df_logistics_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"thirty_day_moving_inventory\": thirty_day_moving_inventory}\n",
        "\n",
        "pandas_134()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kz9MpOQ0OVi",
        "outputId": "3569c34c-bb65-42a0-dfbb-92c2b151275d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# From DataFrame `df_sports_results`, extract top three teams based on 'Scores', sorting first, saving top teams as `top_teams`.\n",
        "@check_pandas_135\n",
        "def pandas_135(df_sports_results):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"top_teams\": top_teams}\n",
        "\n",
        "pandas_135()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mteVTE_K0OVj",
        "outputId": "17628844-0abb-4fde-b8c3-c55eba1c8d26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_network_activity` statistics to calculate z-scores for 'Bandwidth', storing in column 'ZscoreBandwidth' as `network_with_zscore`.\n",
        "@check_pandas_136\n",
        "def pandas_136(df_network_activity):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"network_with_zscore\": network_with_zscore}\n",
        "\n",
        "pandas_136()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGmgHkvK0OVk",
        "outputId": "98b034af-f9a7-4585-d521-5f855e4de3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Perform inplace boolean update of `df_market_responses` setting all 'ResponseTime' > 300 to 300, saving updated DataFrame.\n",
        "@check_pandas_137\n",
        "def pandas_137(df_market_responses):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_market_responses\": df_market_responses}\n",
        "\n",
        "pandas_137()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DlXTttj0OVk",
        "outputId": "ddb86e58-fd8f-431e-f08c-ac5a3092d720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Analyze DataFrame `df_social_behaviors` applying transform with a custom function to 'EngagementRate' to normalize within each 'Group' by z-score, storing as 'NormalizedEngagementRate'.\n",
        "@check_pandas_138\n",
        "def pandas_138(df_social_behaviors):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_social_behaviors\": df_social_behaviors}\n",
        "\n",
        "pandas_138()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTHlOyL30OVv",
        "outputId": "a26ba643-3866-406d-ccf0-337ad9b23884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_product_launch` to derive 'ResponseRate' from 'Inquiries' divided by 'Sales', multiplied by 100, storing as `launch_responses`.\n",
        "@check_pandas_139\n",
        "def pandas_139(df_product_launch):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"launch_responses\": launch_responses}\n",
        "\n",
        "pandas_139()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ic03g7c0OVw",
        "outputId": "30c8b15b-e4e0-4856-9330-41b82b495146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `create_series_from_dict` that takes a dictionary `input_dict` as an argument, and returns a pandas Series with the dictionary keys as the Series index.\n",
        "@check_pandas_140\n",
        "def pandas_3():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"create_series_from_dict\": create_series_from_dict}\n",
        "\n",
        "pandas_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Pa782Zl0OVx",
        "outputId": "278c3024-43e5-4e53-ac21-d21212eab6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `filter_series_positive` that takes a pandas Series `data_series` and returns a new Series containing only the elements where the value is positive.\n",
        "@check_pandas_141\n",
        "def pandas_4():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filter_series_positive\": filter_series_positive}\n",
        "\n",
        "pandas_4()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b50cbM8y0OV0",
        "outputId": "e95bed15-3a78-40ef-b18f-935fab37b0b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `rename_dataframe_columns` that accepts a DataFrame `df` and a dictionary `column_mapping`, and returns the DataFrame with renamed columns according to the mapping.\n",
        "@check_pandas_142\n",
        "def pandas_142():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"rename_dataframe_columns\": rename_dataframe_columns}\n",
        "\n",
        "pandas_142()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IqIPdfv0OV1",
        "outputId": "89214073-9127-4879-8790-2d24a7f81d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `drop_nan_rows` that takes a DataFrame `input_df` and returns a new DataFrame with all rows containing any NaN values removed.\n",
        "@check_pandas_143\n",
        "def pandas_143():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"drop_nan_rows\": drop_nan_rows}\n",
        "\n",
        "pandas_143()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5Kh8Gfy0OV2",
        "outputId": "7e509604-8111-476a-ac32-0d9b6ea125f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Construct a function `fill_missing_with_mean` which takes a DataFrame `df` and fills missing values in each numeric column with the mean of that column, returning the modified DataFrame.\n",
        "@check_pandas_144\n",
        "def pandas_144():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"fill_missing_with_mean\": fill_missing_with_mean}\n",
        "\n",
        "pandas_144()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BUthYe20OV3",
        "outputId": "1acf41ab-d0be-4c41-fe5f-3a38a80026ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `calculate_group_means` that takes a DataFrame `df` and a column name `group_col`, grouping by `group_col`, then returning the mean of each group as a Series.\n",
        "@check_pandas_145\n",
        "def pandas_145():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_group_means\": calculate_group_means}\n",
        "\n",
        "pandas_145()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSGLY8VT0OV3",
        "outputId": "9a033923-d526-427b-8b90-22dc7b503548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `subset_dataframe_label` that accepts a DataFrame `df`, a list `rows` of row labels, and returns a subset DataFrame containing only those rows.\n",
        "@check_pandas_146\n",
        "def pandas_146():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"subset_dataframe_label\": subset_dataframe_label}\n",
        "\n",
        "pandas_146()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh4C037G0OV4",
        "outputId": "86816931-70cf-4115-867f-5869308fff57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `merge_dataframes_on_key` that takes two DataFrames `df1`, `df2`, and a string `key`, merging them on the shared key column and returning the merged DataFrame.\n",
        "@check_pandas_147\n",
        "def pandas_147():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"merge_dataframes_on_key\": merge_dataframes_on_key}\n",
        "\n",
        "pandas_147()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4xotUB-0OV5",
        "outputId": "49ba68e1-30be-4be8-90f3-f0ca08ff443f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `aggregate_sales_by_region` which accepts a DataFrame `sales_df` that includes columns 'Region' and 'Sales', and returns a DataFrame with the total sales per region.\n",
        "@check_pandas_148\n",
        "def pandas_148():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"aggregate_sales_by_region\": aggregate_sales_by_region}\n",
        "\n",
        "pandas_148()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzHy8p_-0OV6",
        "outputId": "e3b61ce9-832e-457c-c135-aacc887cfad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `pivot_table_for_analysis` that takes a DataFrame `df` and strings `index`, `columns`, `values`, and returns a pivot table using those specifications.\n",
        "@check_pandas_149\n",
        "def pandas_149():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"pivot_table_for_analysis\": pivot_table_for_analysis}\n",
        "\n",
        "pandas_149()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEfnsvWx0OV6",
        "outputId": "ae905acf-dd8b-4db7-a0b5-0b5c8d857711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `calculate_rolling_average` that accepts a DataFrame `df` and an integer `window` to compute the rolling average of a numeric column `column_name`, returning the updated series.\n",
        "@check_pandas_150\n",
        "def pandas_150():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_rolling_average\": calculate_rolling_average}\n",
        "\n",
        "pandas_150()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VBR86m00OV7",
        "outputId": "95a2e706-4d80-48cd-d122-7dbf81b3bc0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Construct a function `resample_time_series` which takes a time-indexed DataFrame `time_df` and a frequency string `freq`, resampling the DataFrame to the new frequency and summing, returning the result.\n",
        "@check_pandas_151\n",
        "def pandas_151():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"resample_time_series\": resample_time_series}\n",
        "\n",
        "pandas_151()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vLFzSm20OV7",
        "outputId": "e86b22f1-977c-4fd2-ae91-31471b1f3beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `expand_string_columns` that takes a DataFrame `df` and a list of columns `string_columns`, expanding each string column to lowercase, and returns the modified DataFrame.\n",
        "@check_pandas_152\n",
        "def pandas_152():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"expand_string_columns\": expand_string_columns}\n",
        "\n",
        "pandas_152()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yli7Px30OV8",
        "outputId": "b2354384-bd46-415a-d796-e9c0df2a36c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `convert_to_datetime_index` that accepts a DataFrame `df` and a column name `date_col`, converting it to a DateTimeIndex, and returning the updated DataFrame.\n",
        "@check_pandas_153\n",
        "def pandas_153():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"convert_to_datetime_index\": convert_to_datetime_index}\n",
        "\n",
        "pandas_153()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBwhIJSX0OV9",
        "outputId": "f387d918-46f4-485e-c4e1-579ecfe1bb3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `identify_and_remove_outliers` that identifies outliers in a Series `data_series` using a specified `threshold` by removing the values outside of the `threshodl` multiplied by the standard deviation from the mean.\n",
        "@check_pandas_154\n",
        "def pandas_154():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"identify_and_remove_outliers\": identify_and_remove_outliers}\n",
        "\n",
        "pandas_154()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYLCkhV20OV9",
        "outputId": "28585e7a-4c44-4deb-835a-a38cdbd0fbc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `calculate_percentage_change` which computes the percentage change over time for a Series `time_series` and returns the updated Series with NaN for the first entry.\n",
        "@check_pandas_155\n",
        "def pandas_155():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_percentage_change\": calculate_percentage_change}\n",
        "\n",
        "pandas_155()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp_pXPU70OV-",
        "outputId": "4b1763a4-5736-428c-919d-4c18a87a5344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `categorize_based_on_values` which takes a DataFrame `df`, a column `categorical_col`, and returns a DataFrame with additional column 'Category' based on ranges in `categorical_col` with labels ['Low', 'Medium', 'High'] and bins [0, 100, 200, 300].\n",
        "@check_pandas_156\n",
        "def pandas_156():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"categorize_based_on_values\": categorize_based_on_values}\n",
        "\n",
        "pandas_156()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRitCqR60OV-",
        "outputId": "9e723f92-383b-4eaa-cc92-4a95780af118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `shift_dataframe_rows` that takes a DataFrame `df` and an integer `periods`, shifting all rows by the specified number of periods and returning the DataFrame.\n",
        "@check_pandas_157\n",
        "def pandas_157():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"shift_dataframe_rows\": shift_dataframe_rows}\n",
        "\n",
        "pandas_157()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkLR58xE0OV_",
        "outputId": "ed64621e-aa0e-4723-b5ad-02110f0e5c90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `aggregate_and_flatten_grouped` that takes a grouped DataFrame `group_df` and returns a flattened DataFrame with 'sum' and 'count' aggregation for each group and reseted index.\n",
        "@check_pandas_158\n",
        "def pandas_158():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"aggregate_and_flatten_grouped\": aggregate_and_flatten_grouped}\n",
        "\n",
        "pandas_158()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-rVUhUp0OWA",
        "outputId": "76a42847-1810-41e2-c719-721dae3d34e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Construct a function named `remove_duplicates_by_columns` that takes a DataFrame `df` and a list `subset_columns`, and removes duplicate rows based on these columns, returning the resulting DataFrame.\n",
        "@check_pandas_159\n",
        "def pandas_159():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"remove_duplicates_by_columns\": remove_duplicates_by_columns}\n",
        "\n",
        "pandas_159()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDlZ-W500OWA",
        "outputId": "c7ae4e51-13ee-46d6-f811-47563c4921fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `calculate_memory_usage` that takes a DataFrame `df` and returns the total memory usage in MB, both with and without optimizations for all columns possible.\n",
        "@check_pandas_160\n",
        "def pandas_160():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_memory_usage\": calculate_memory_usage}\n",
        "\n",
        "pandas_160()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1gzeMm-0OWB",
        "outputId": "c0132db1-93e6-431a-9ace-3079a26d0396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `map_values_with_dict` which accepts a DataFrame `df`, a column `target_col`, and a dictionary `value_map`, returning the updated DataFrame after mapping.\n",
        "@check_pandas_161\n",
        "def pandas_161():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"map_values_with_dict\": map_values_with_dict}\n",
        "\n",
        "pandas_161()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9OdLGlS0OWB",
        "outputId": "ac34d852-e11e-4285-c71d-f77545e6a192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `select_top_n_rows_based_on_column` that takes a DataFrame `df`, a column `target_col`, and an integer `n`, and returns the top `n` rows sorted by `target_col`.\n",
        "@check_pandas_162\n",
        "def pandas_162():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"select_top_n_rows_based_on_column\": select_top_n_rows_based_on_column}\n",
        "\n",
        "pandas_162()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuwFilD40OWC",
        "outputId": "c211961a-a7c5-4313-9b68-beae328b99a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `replace_substrings_in_column` that takes a DataFrame `df`, a column `text_col`, a string `old`, and a string `new`, replacing all occurrences of `old` with `new` in `text_col`.\n",
        "@check_pandas_163\n",
        "def pandas_163():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"replace_substrings_in_column\": replace_substrings_in_column}\n",
        "\n",
        "pandas_163()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97xDPFfH0OWD",
        "outputId": "9123590f-160d-4127-f582-6f2c4c46c032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `apply_discretization_binner` which bins Series `data_series` into a specified number of discrete intervals `n_bins` and returns the binned Series.\n",
        "@check_pandas_164\n",
        "def pandas_164():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"apply_discretization_binner\": apply_discretization_binner}\n",
        "\n",
        "pandas_164()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_76uaMB0OWD",
        "outputId": "e01fad6c-fa63-42c9-e0a1-5dcb03acfbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `generate_descriptive_statistics` that takes a DataFrame `df` and returns a DataFrame with descriptive statistics such as mean, median, and standard deviation for all numeric columns.\n",
        "@check_pandas_165\n",
        "def pandas_165():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"generate_descriptive_statistics\": generate_descriptive_statistics}\n",
        "\n",
        "pandas_165()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxDCOS_D0OWD",
        "outputId": "2b8d3afd-56e9-4fd3-bdd9-2fcc0000e7a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `convert_column_dtype` that accepts a DataFrame `df`, a column name `col`, and a data type `new_type`, and returns the DataFrame with `col` converted to `new_type`.\n",
        "@check_pandas_166\n",
        "def pandas_166():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"convert_column_dtype\": convert_column_dtype}\n",
        "\n",
        "pandas_166()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxNCaE1g0OWE",
        "outputId": "ea74891a-c230-4289-9ea5-12c69d368c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `sort_dataframe_by_multiple_columns` taking DataFrame `df` and a list `columns_list` to sort the DataFrame by these columns, returning the sorted DataFrame.\n",
        "@check_pandas_167\n",
        "def pandas_167():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sort_dataframe_by_multiple_columns\": sort_dataframe_by_multiple_columns}\n",
        "\n",
        "pandas_167()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBqTpjO50OWE",
        "outputId": "c7507d0b-7278-403c-ebb0-0ef7f9bb1134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `create_time_based_features` which accepts a DataFrame `time_df` with a 'Timestamp' column and returns the DataFrame with new columns for hour, day, and month.\n",
        "@check_pandas_168\n",
        "def pandas_168():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"create_time_based_features\": create_time_based_features}\n",
        "\n",
        "pandas_168()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0X5SSdd0OWE",
        "outputId": "f5f199c0-5138-4fba-ac63-658badf8cd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `analyze_sales_data` that takes a DataFrame `sales_df` with columns 'Date', 'Region', and 'Sales'. The function should: Convert 'Date' to a DateTime object; Filter out any rows where 'Sales' is negative; Group by 'Region' to calculate the total and average sales; Return a DataFrame with columns 'Region', 'TotalSales', 'AverageSales';\n",
        "@check_pandas_169\n",
        "def pandas_169():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"analyze_sales_data\": analyze_sales_data}\n",
        "\n",
        "pandas_169()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLJ45qR30OWF",
        "outputId": "a4c7b60f-5135-4537-b5d5-f96fe5d7b7ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `clean_and_merge_datasets` that takes two DataFrames `df_left` and `df_right`, and: Fills NA values in `df_left` with 0; Drops any duplicate rows in `df_right`; Merges the cleaned DataFrames on a common column 'Key', using an outer join; Returns the merged DataFrame sorted by 'Key';\n",
        "@check_pandas_170\n",
        "def pandas_170():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"clean_and_merge_datasets\": clean_and_merge_datasets}\n",
        "\n",
        "pandas_170()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjUtmLcA0OWF",
        "outputId": "dba68169-68e9-4ca4-cba7-f62282965577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `process_sensor_data_batch` that receives a DataFrame `sensor_df` containing 'SensorID', 'ReadingValue', 'Timestamp'. Convert 'Timestamp' to datetime format; Ensure all 'ReadingValue' entries are non-negative; Calculate the mean and standard deviation of 'ReadingValue' for each 'SensorID'; Return a DataFrame with 'SensorID', 'MeanReading', 'StdDevReading';\n",
        "@check_pandas_171\n",
        "def pandas_171():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"process_sensor_data_batch\": process_sensor_data_batch}\n",
        "\n",
        "pandas_171()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHihFXw50OWF",
        "outputId": "c369d422-81dd-4bbc-ae33-fe6b825d3a12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Construct a function `analyze_customer_behaviors` to handle a DataFrame `customer_df` with columns 'CustomerID', 'PurchaseAmount', 'VisitTimestamp'. Convert 'VisitTimestamp' to a DateTimeIndex; Filter to include only purchases greater than a specified `min_purchase`; Group by 'CustomerID' to determine the total and count of purchases; Return a DataFrame with 'CustomerID', 'TotalPurchases', 'NumberVisits', and attach the most recent visit date;\n",
        "@check_pandas_172\n",
        "def pandas_172():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"analyze_customer_behaviors\": analyze_customer_behaviors}\n",
        "\n",
        "pandas_172()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFbeMo6A0OWG",
        "outputId": "70e99432-32b0-4ec1-f3c8-fc927cbd3afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `transform_financial_data` that processes a DataFrame `financial_df` including columns 'AccountID', 'TransactionDate', 'Amount'. Parse 'TransactionDate' into datetime and set as index; Filter 'Amount' to exclude NaN and zero values; Extract month and year from 'TransactionDate' into new columns `Month`, `Year`; Group by 'AccountID' and 'Year' to summarize monthly 'Amount' into sum and mean, returning a structured DataFrame;\n",
        "@check_pandas_173\n",
        "def pandas_173():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"transform_financial_data\": transform_financial_data}\n",
        "\n",
        "pandas_173()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifUwLu2S0OWG",
        "outputId": "0f38463d-6010-47b0-fe1a-5e4ef3d83f18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `aggregate_weather_data` for a DataFrame `weather_df` with fields 'StationID', 'Temp', 'Humidity', 'ObservationTime'. Convert 'ObservationTime' to a DateTimeIndex; Filter to retain records with positive 'Temp' and 'Humidity'; Resample to daily frequency, taking the mean for each day; Return a DataFrame grouped by 'StationID' with columns for daily average 'Temp' and 'Humidity';\n",
        "@check_pandas_174\n",
        "def pandas_174():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"aggregate_weather_data\": aggregate_weather_data}\n",
        "\n",
        "pandas_174()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olxT_s0D0OWH",
        "outputId": "dc522968-5686-45b8-d9ac-010dcf97d796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `standardize_student_record` to clean a DataFrame `student_df` featuring 'Name', 'Score', 'SubmissionDate'. Standardize 'Name' to have a capitalized first letter; Address missing 'Score' values by assigning the median score; Standardize 'SubmissionDate' to a consistent format and compute 'DaysSinceSubmission'; Return a DataFrame with standardized names, computed days since submission, and filled scores;\n",
        "@check_pandas_175\n",
        "def pandas_175():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"standardize_student_record\": standardize_student_record}\n",
        "\n",
        "pandas_175()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsF5zLjw0OWH",
        "outputId": "f549953f-4792-487d-9f52-eaf5ae8f0288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `construct_inventory_report` that takes a DataFrame `inventory_df` with 'ItemID', 'Quantity', 'RestockDate'. Parse 'RestockDate' to ensure it's in datetime format; Identify items needing restock by checking 'Quantity' against the `threshold`; Provide a summary count of items needing restock by month; Return a detailed DataFrame with 'ItemID', 'Quantity', 'DaysUntilRestock', plus a monthly summary DataFrame;\n",
        "@check_pandas_176\n",
        "def pandas_176():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"construct_inventory_report\": construct_inventory_report}\n",
        "\n",
        "pandas_176()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7cfdCdv0OWI",
        "outputId": "9b01a718-4496-477c-c325-d0827b98e3ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `optimize_sales_forecast` that works on DataFrame `forecast_df` with columns 'Product', 'ProjectedSales', 'ForecastDate'. Convert 'ForecastDate' to DateTime format; Apply forward fill to handle missing 'ProjectedSales' values; Conduct a rolling window analysis to compute the 3-month moving average of sales; Return an extended DataFrame with moving averages along with original columns;\n",
        "@check_pandas_177\n",
        "def pandas_177():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"optimize_sales_forecast\": optimize_sales_forecast}\n",
        "\n",
        "pandas_177()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei3kCCqF0OWK",
        "outputId": "1171ca99-9ecb-4329-de2b-b7cfcca82d26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `summarize_employee_performance` that processes DataFrame `performance_df` with 'EmployeeID', 'Score', 'ReviewDate'. Ensure 'ReviewDate' is converted into a datetime object; Replace missing 'Score' with the lowest non-zero score; Group by 'EmployeeID' to compute total and average score; Generate a DataFrame highlighting top performers with scores above a specified percentile score; Audit history, including evaluation of performance improvement over time;\n",
        "@check_pandas_178\n",
        "def pandas_178():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"summarize_employee_performance\": summarize_employee_performance}\n",
        "\n",
        "pandas_178()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT8_tKXR0OWL",
        "outputId": "fbc080cd-c19c-4863-be8e-1431dee70cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `double_series_values` that takes a Series `input_series` and returns a Series with all values doubled.\n",
        "@check_pandas_179\n",
        "def pandas_179():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"double_series_values\": double_series_values}\n",
        "\n",
        "pandas_179()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk4gjKFB0OWL",
        "outputId": "97a807e2-9194-40d9-c379-6dbdc3c9558e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `replace_zeros_with_mean` that takes a Series `data_series` and replaces all 0 values with the mean of the Series, returning the modified Series.\n",
        "@check_pandas_180\n",
        "def pandas_180():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"replace_zeros_with_mean\": replace_zeros_with_mean}\n",
        "\n",
        "pandas_180()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0j9lLI60OWL",
        "outputId": "141442f9-452b-42ee-a0cb-d5a00bb5e8dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `standardize_column_names` that accepts a DataFrame `df` and returns it with all column names set to lowercase.\n",
        "@check_pandas_181\n",
        "def pandas_181():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"standardize_column_names\": standardize_column_names}\n",
        "\n",
        "pandas_181()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y73z1hBe0OWM",
        "outputId": "0c96a5d5-010a-45f8-ecb0-caafbacc5be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `drop_duplicate_rows` that receives a DataFrame `df` and returns it with duplicate rows removed.\n",
        "@check_pandas_182\n",
        "def pandas_182():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"drop_duplicate_rows\": drop_duplicate_rows}\n",
        "\n",
        "pandas_182()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0zVXfdo0OWM",
        "outputId": "bbde00e1-97b1-4f93-f308-b092b83e1366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `calculate_column_sums` that takes a DataFrame `df` and returns a Series containing the sum of each column.\n",
        "@check_pandas_183\n",
        "def pandas_183():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_column_sums\": calculate_column_sums}\n",
        "\n",
        "pandas_183()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idWBn1xr0OWM",
        "outputId": "432ebb86-0027-4bf2-b4bd-ef4faa99e6e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `extract_date_parts` that takes a Series `dates` of datetime objects and returns a DataFrame with columns 'Year', 'Month', and 'Day'.\n",
        "@check_pandas_184\n",
        "def pandas_184():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"extract_date_parts\": extract_date_parts}\n",
        "\n",
        "pandas_184()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJhJ-Jsq0OWN",
        "outputId": "593947c3-530c-4b21-8369-630376abf781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `concat_strings_in_column` that, given a DataFrame `df` and a column `text_col`, concatenates all strings in that column with a space in between, returning the result string.\n",
        "@check_pandas_185\n",
        "def pandas_185():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"concat_strings_in_column\": concat_strings_in_column}\n",
        "\n",
        "pandas_185()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K51nC8V_0OWO",
        "outputId": "2d14436f-33de-4681-e6fe-75d59195295a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `sort_by_index_descending` that accepts a DataFrame `df` and returns it sorted by its index in descending order.\n",
        "@check_pandas_186\n",
        "def pandas_186():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sort_by_index_descending\": sort_by_index_descending}\n",
        "\n",
        "pandas_186()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jcGeVte0OWP",
        "outputId": "926d4100-3c4a-4bdf-94c4-4932a382ae00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `filter_by_threshold` to take a DataFrame `df` and a column name `col`, returning a DataFrame including only rows where `col` is above a given threshold.\n",
        "@check_pandas_187\n",
        "def pandas_187():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filter_by_threshold\": filter_by_threshold}\n",
        "\n",
        "pandas_187()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGe4mCIo0OWQ",
        "outputId": "f221dd77-5321-4155-f087-59f23a6a852e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `get_unique_values` that takes a DataFrame `df` and a column `col`, returning a sorted array of unique values in the specified column.\n",
        "@check_pandas_188\n",
        "def pandas_188():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"get_unique_values\": get_unique_values}\n",
        "\n",
        "pandas_188()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzOqXlmW0OWQ",
        "outputId": "cfbfa786-800f-4b8f-bed6-f5d234b1db1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `append_row_to_dataframe` that takes a DataFrame `df` and a dictionary `row_dict`, appending the dictionary as a new row, and returning the updated DataFrame.\n",
        "@check_pandas_189\n",
        "def pandas_189():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"append_row_to_dataframe\": append_row_to_dataframe}\n",
        "\n",
        "pandas_189()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7MYSWIK0OWQ",
        "outputId": "8a297c6f-020f-406d-d8b7-62d2c3df6a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Construct a function `reset_index_and_name` that takes a DataFrame `df` and returns it with its index reset and the name of the index set to 'NewIndex'.\n",
        "@check_pandas_190\n",
        "def pandas_190():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"reset_index_and_name\": reset_index_and_name}\n",
        "\n",
        "pandas_190()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJaABHHf0OWR",
        "outputId": "a46a245d-a76b-435d-937c-06b3e2db6c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `swap_dataframe_columns` that accepts a DataFrame `df` and two column names `col1` and `col2`, swapping the values of these columns.\n",
        "@check_pandas_191\n",
        "def pandas_191():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"swap_dataframe_columns\": swap_dataframe_columns}\n",
        "\n",
        "pandas_191()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCpHzNqa0OWR",
        "outputId": "67fe22e6-902f-4c92-9ee3-36581924c1e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `rename_index_label` which receives a DataFrame `df`, renames its first index label to 'FirstRow', and returns the DataFrame.\n",
        "@check_pandas_192\n",
        "def pandas_192():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"rename_index_label\": rename_index_label}\n",
        "\n",
        "pandas_192()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maZv6iyN0OWe",
        "outputId": "e828b8be-0fcb-485b-800c-51feca3ba665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `calculate_frequency_table` that, given a DataFrame `df` and a column `cat_col`, returns a DataFrame with a frequency count of each category with columns Category and count.\n",
        "@check_pandas_193\n",
        "def pandas_193():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_frequency_table\": calculate_frequency_table}\n",
        "\n",
        "pandas_193()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqL0wtse0OWf",
        "outputId": "fa33fe4d-1131-44e5-9b94-7fad23684079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `remove_negative_entries` that takes a Series `numeric_series` and returns a Series with all negative entries removed.\n",
        "@check_pandas_194\n",
        "def pandas_194():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"remove_negative_entries\": remove_negative_entries}\n",
        "\n",
        "pandas_194()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5TMhzVV0OWf",
        "outputId": "3d50c518-957c-4509-9d72-5cff38082869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `sort_column_values` that takes a DataFrame `df` and column name `col`, returning `df` sorted by `col` values in ascending order.\n",
        "@check_pandas_195\n",
        "def pandas_195():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sort_column_values\": sort_column_values}\n",
        "\n",
        "pandas_195()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpk2_bfc0OWg",
        "outputId": "a92dea10-5e1a-4ceb-f889-03e6ca03ba13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `drop_columns_by_name` that accepts a DataFrame `df` and a list of column names `drop_cols`, removing these columns and returning the modified DataFrame.\n",
        "@check_pandas_196\n",
        "def pandas_196():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"drop_columns_by_name\": drop_columns_by_name}\n",
        "\n",
        "pandas_196()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2phzw6l_0OWg",
        "outputId": "ef160e7f-1226-42e2-911e-6c8bf524dfc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `strip_whitespace` that takes a DataFrame `df` and trims leading and trailing whitespace from all string entries.\n",
        "@check_pandas_197\n",
        "def pandas_197():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"strip_whitespace\": strip_whitespace}\n",
        "\n",
        "pandas_197()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxAlVSHx0OWh",
        "outputId": "cd2f9b34-c90a-4471-b89c-1ca8a7198dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `duplicate_last_column` that receives a DataFrame `df` and duplicates its last column, appending the duplicate to the right of the DataFrame named as the original column with '_copy' appended.\n",
        "@check_pandas_198\n",
        "def pandas_198():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"duplicate_last_column\": duplicate_last_column}\n",
        "\n",
        "pandas_198()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-AqlTIQ0OWi",
        "outputId": "4bab8bc6-a3b7-48a4-d33d-e10468c40bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `filter_top_n_rows_by_column` that takes a DataFrame `df`, a column `col`, and an integer `n`, returning the top n rows sorted by values in `col`.\n",
        "@check_pandas_199\n",
        "def pandas_199():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filter_top_n_rows_by_column\": filter_top_n_rows_by_column}\n",
        "\n",
        "pandas_199()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoA3PvjW0OWj",
        "outputId": "4df97284-1003-4a9e-c5cb-733169ac6856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `calculate_range_of_numeric_series` that takes a Series `numeric_series` and returns the range (max - min) of its values.\n",
        "@check_pandas_200\n",
        "def pandas_200():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_range_of_numeric_series\": calculate_range_of_numeric_series}\n",
        "\n",
        "pandas_200()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "excalibur",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}